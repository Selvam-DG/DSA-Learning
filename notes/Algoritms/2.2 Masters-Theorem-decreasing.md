# Master Theorem for Decreasing / Subtractive Recurrence Relations

This version of the Master Theorem handles recurrence relations of the form:

T(n) = aT(n - b) + f(n)

Where:
- `a > 0`, `b > 0`
- `f(n)` is a function that represents the non-recursive work at each level
- These types of recurrences often appear in **dynamic programming** and **exponential recursion** problems

---

##  Common Patterns and Their Time Complexities

| Recurrence                    | Time Complexity    | Notes                      |
|------------------------------|--------------------|----------------------------|
| T(n) = T(n - 1) + 1          | O(n)               | Linear addition            |
| T(n) = T(n - 1) + n          | O(n²)              | Sum of first n numbers     |
| T(n) = T(n - 1) + log n      | O(n log n)         | Sum of log values          |
| T(n) = T(n - 1) + n²         | O(n³)              | Sum of squares             |
| T(n) = T(n - k) + 1          | O(n), for any k>0  | Steps of size k            |
| T(n) = 2T(n - 1) + 1         | O(2ⁿ)              | Exponential recursion      |
| T(n) = 3T(n - 1) + 1         | O(3ⁿ)              | Faster exponential         |

---

##  General Form
T(n) = aT(n - b) + f(n)

Where:
- `a > 0`, `b > 0`
- `f(n)` is polynomial or logarithmic, typically `O(n^k)`

---

###  Analysis Based on 'a'

####  Case 1: `a < 1`
- Time Complexity:  

T(n) = O(f(n)) = O(n^k)


#### Case 2: `a = 1`
- Time Complexity:  

T(n) = O(n * f(n)) = O(n * n^k) = O(n^{k+1})


#### Case 3: `a > 1`
- Time Complexity:
  
T(n) = O(f(n) * a^{n/b})

This leads to exponential time complexities when `a > 1`.

---

## 📌 Examples Explained

### Example 1: Linear Time

T(n) = T(n - 1) + 1

→ T(n) = O(n)


### Example 2: Quadratic Time
T(n) = T(n - 1) + n

→ T(n) = O(n²)

Because it becomes the sum:  
T(n) = n + (n-1) + (n-2) + ... + 1 = n(n+1)/2


### Example 3: Exponential Time
T(n) = 2T(n - 1) + 1
→ T(n) = O(2^n)


