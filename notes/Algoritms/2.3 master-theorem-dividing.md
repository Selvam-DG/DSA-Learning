#  Master Theorem for Divide and Conquer Recurrences

The **Master Theorem** provides a way to determine the time complexity of recursive algorithms that follow this pattern:

T(n) = aT(n/b) + f(n)

Where:
- `a ≥ 1` is the number of subproblems
- `n/b` is the size of each subproblem
- `f(n)` is the cost of dividing and combining the results

---

## Master Theorem Cases

Let `f(n) = Θ(n^d)` for some constant `d ≥ 0`.

Compare `f(n)` to `n^log_b(a)`:

### Case 1: Subproblem dominates
If:

f(n) = O(n^d) where d < log_b(a)

Then:

T(n) = Θ(n^log_b(a))

**Example**:

T(n) = 2T(n/2) + 1 → log_b(a) = log₂(2) = 1

→ f(n) = O(1) = n⁰ ⇒ d = 0 < 1 → Case 1

→ T(n) = Θ(n)

---

### Case 2: Balanced
If:

T(n) = Θ(n^d · log n)

**Example**:

T(n) = 2T(n/2) + n → log₂(2) = 1, f(n) = n = n^1 ⇒ Case 2

→ T(n) = Θ(n log n)

---

### Case 3: Combining dominates
If:

f(n) = Ω(n^d) where d > log_b(a), and regularity condition holds:

a·f(n/b) ≤ c·f(n) for some c < 1 and sufficiently large n

Then:

T(n) = Θ(f(n))

**Example**:

T(n) = 2T(n/2) + n² → log₂(2) = 1, f(n) = n² = n^2 ⇒ d = 2 > 1

→ T(n) = Θ(n²)

---

##  Recap Table

| Recurrence Form                  | Case | Time Complexity        |
|----------------------------------|------|-------------------------|
| T(n) = 2T(n/2) + 1               | 1    | Θ(n)                    |
| T(n) = 2T(n/2) + n               | 2    | Θ(n log n)              |
| T(n) = 2T(n/2) + n²              | 3    | Θ(n²)                   |
| T(n) = 3T(n/4) + n               | 2    | Θ(n log n)              |
| T(n) = 4T(n/2) + n               | 1    | Θ(n²)                   |
| T(n) = 7T(n/2) + n²               | 3    | Θ(n^2.81)               |
| T(n) = 8T(n/2) + n²              | 1   | Θ(n^3)                   |
| T(n) = 16T(n/2) + n²             | 1   | Θ(n^4)                   |
| T(n) = T(n/2) + n                 | 3   | Θ(n)                   |
| T(n) = 2T(n/2) + n²logn           | 3   | Θ(n²logn)                |


---

## Formula Summary

Given:

T(n) = aT(n/b) + Θ(n^d)


Then:

- If `d < log_b(a)` → T(n) = Θ(n^log_b(a))
- If `d = log_b(a)` → T(n) = Θ(n^d · log n)
- If `d > log_b(a)` and regularity condition holds → T(n) = Θ(n^d)

---

## References

- [Abdul Bari - Master Theorem Lecture](https://www.youtube.com/watch?v=OynWkEj0S-s&list=PLDN4rrl48XKpZkf03iYFl-O29szjTrs_O&index=27&ab_channel=AbdulBari)



